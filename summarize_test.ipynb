{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telegram_models import TelegramExport\n",
    "\n",
    "chats = TelegramExport.parse_file('result.json').chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сергей 45932 messages\n"
     ]
    }
   ],
   "source": [
    "chat = next(chat for chat in chats if chat.name == 'Сергей')\n",
    "print(chat.name, len(chat.messages), 'messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "my_name = 'Cyber Potato'\n",
    "my_real_name = 'Денис'\n",
    "\n",
    "def process_name(name):\n",
    "    if name == my_name:\n",
    "        return my_real_name\n",
    "    return 'Собеседник'\n",
    "\n",
    "def get_random_chunk(length):\n",
    "    start = random.randint(0, len(chat.messages) - length)\n",
    "    return chat.messages[start:start+length]\n",
    "\n",
    "def get_random_chunk_ensure_text(length):\n",
    "    while True:\n",
    "        chunk = get_random_chunk(length)\n",
    "        if all(message.text for message in chunk):\n",
    "            return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Денис: пхахахахахахах думаю норм\n",
      "Денис: дед оценит\n",
      "Собеседник: Надо лабы спидранить\n",
      "Денис: Надо!\n",
      "Собеседник: Я кажется понял чё он хочет в моей лабе\n",
      "Денис: Ну-ка\n",
      "Собеседник: Конвертер лонга в стринг\n",
      "Собеседник: Но я не пойму, он хочет чтобы я по ссылке запись делал, или ретёрнил ответ\n",
      "Денис: Я думаю по ссылке, но используя String\n",
      "Собеседник: хм\n",
      "Собеседник: хм\n",
      "Собеседник: Какие ты сниппеты для плюсов поставил\n",
      "Денис: ты имеешь в виду шорткаты типа libsst?\n",
      "Собеседник: да\n",
      "Денис: пока никакие\n",
      "Денис: а ты?\n",
      "Собеседник: Ты свои поставил?\n",
      "Собеседник: Я просто видел ты их использовал\n",
      "Денис: я использовал сниппеты для си\n",
      "Собеседник: ?\n"
     ]
    }
   ],
   "source": [
    "text = '\\n'.join([\n",
    "    f'{process_name(message.from_)}: {message.text}'\n",
    "    for message in get_random_chunk_ensure_text(20)\n",
    "])\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize using Russian mBART model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using model: https://huggingface.co/Kirili4ik/mbart_ruDialogSum  \n",
    "From the developers of [@summarization_bot](https://t.me/summarization_bot)\n",
    "\n",
    "Possible others:\n",
    "- https://huggingface.co/IlyaGusev/rugpt3medium_sum_gazeta\n",
    "- https://huggingface.co/UrukHan/t5-russian-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fix error\n",
    "%pip uninstall protobuf -y\n",
    "%pip install protobuf==3.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartTokenizer, MBartForConditionalGeneration\n",
    "\n",
    "# Download model and tokenizer\n",
    "model_name = \"Kirili4ik/mbart_ruDialogSum\"   \n",
    "tokenizer =  MBartTokenizer.from_pretrained(model_name)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "    input_ids = tokenizer(\n",
    "        [text],\n",
    "        max_length=600,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        top_k=0,\n",
    "        num_beams=3,\n",
    "        no_repeat_ngram_size=3,\n",
    "        length_penalty=1.5,\n",
    "        max_new_tokens=100,\n",
    "    )[0]\n",
    "\n",
    "    summary = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Денис использовал сниппеты для плюсов в своей лабе.\n"
     ]
    }
   ],
   "source": [
    "print(summarize(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize using Sber ruT5-large model API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homepage: https://cloud.ru/ru/datahub/rugpt3family/summarizer\n",
    "\n",
    "API reference: https://api.aicloud.sbercloud.ru/public/v2/summarizator/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ratelimit\n",
    "%pip install backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://api.aicloud.sbercloud.ru/public/v2/summarizator/predict'\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ratelimit import limits, RateLimitException\n",
    "from backoff import on_exception, expo\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "@on_exception(expo, RateLimitException, max_tries=8)\n",
    "@limits(calls=90, period=60)  # just for safety\n",
    "def summarize_api(text):\n",
    "    response = requests.post(\n",
    "        base_url,\n",
    "        headers=headers,\n",
    "        json={\n",
    "            'instances': [\n",
    "                {\n",
    "                    \"num_beams\": 16,\n",
    "                    \"length_penalty\": 1.5,\n",
    "                    'text': text,\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'API response: {response.status_code}')\n",
    "\n",
    "    return response.json()['prediction_best']['bertscore']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собеседник : Конвертер лонга в стринг Денис : я думаю по ссылке, или ретёрнил ответ.\n"
     ]
    }
   ],
   "source": [
    "print(summarize_api(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Russian mBART model works better on chat summarization than ruT5-large model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
